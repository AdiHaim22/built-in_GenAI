{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a31d70",
   "metadata": {},
   "source": [
    "\n",
    "# Floorplan Object Removal with DETR + SAM + Background Inpainting\n",
    "\n",
    "This script automatically detects and removes specific objects from architectural floorplans  \n",
    "(e.g. doors, toilets, stoves, closets) by replacing them with background content.\n",
    "\n",
    "The process is fully automatic, robust to missing objects, and supports multiple labels in one run.\n",
    "\n",
    "---\n",
    "\n",
    "##  Features\n",
    "\n",
    "- Detects multiple object types in a single floorplan\n",
    "- Uses a fine-tuned **DETR** model for object detection\n",
    "- Uses **SAM (Segment Anything)** for precise object masks\n",
    "- Falls back to bounding-box masks if SAM fails\n",
    "- Replaces objects using random background images\n",
    "- Does **not crash** if an object is not found\n",
    "- Saves outputs per label: bounding box, mask, background, and final result\n",
    "\n",
    "---\n",
    "\n",
    "##  Supported Object Labels\n",
    "\n",
    "The script processes the following labels (substring matching):\n",
    "\n",
    "- `1stdoor`\n",
    "- `2sdoor`\n",
    "- `toilet`\n",
    "- `stove`\n",
    "- `closet`\n",
    "- `sink`\n",
    "\n",
    "If a label is **not detected** in the floorplan, the script logs a warning and continues.\n",
    "\n",
    "---\n",
    "\n",
    "##  Pipeline Overview\n",
    "\n",
    "1. **Object Detection**\n",
    "   - Run DETR once on the input floorplan\n",
    "   - Collect all detections above a confidence threshold\n",
    "\n",
    "2. **Per-Label Processing**\n",
    "   - Filter detections by label substring\n",
    "   - Select the best candidate (highest score + largest area)\n",
    "\n",
    "3. **Mask Generation**\n",
    "   - Preferred: SAM segmentation using bounding box\n",
    "   - Fallback: rectangular bounding-box mask\n",
    "\n",
    "4. **Background Inpainting**\n",
    "   - Random background selected from a folder\n",
    "   - Mask is feathered for smooth blending\n",
    "   - Object area is replaced with background pixels\n",
    "\n",
    "5. **Result Saving**\n",
    "   - Outputs saved per label in separate folders\n",
    "\n",
    "---\n",
    "\n",
    "##  Output Structure\n",
    "\n",
    "```text\n",
    "Data/Label_Pics_for_Synthetic_Data_Generation/\n",
    "│\n",
    "|\n",
    "├── toilet/\n",
    "│   ├── box.png\n",
    "│   ├── mask.png\n",
    "│   ├── bg_used.png\n",
    "│   └── result.png\n",
    "│\n",
    "├── stove/\n",
    "│   ├── box.png\n",
    "│   ├── mask.png\n",
    "│   ├── bg_used.png\n",
    "│   └── result.png\n",
    "│\n",
    "├── closet/\n",
    "│   └── ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adiha\\Desktop\\GenAi\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\TestPlans\\\\testPlan.PNG'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m s[:\u001b[32m80\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) > \u001b[32m80\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m s\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Load image once\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m image_pil = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGE_PATH\u001b[49m\u001b[43m)\u001b[49m.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     85\u001b[39m W, H = image_pil.size\n\u001b[32m     86\u001b[39m img_np = np.array(image_pil)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adiha\\Desktop\\GenAi\\.venv\\Lib\\site-packages\\PIL\\Image.py:3493\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3492\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3493\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3494\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '.\\\\TestPlans\\\\testPlan.PNG'"
     ]
    }
   ],
   "source": [
    "import os, random, gc, re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "# Path to an example image for testing (relative to Code folder)\n",
    "IMAGE_PATH      = r\"..\\Data\\images_before\\image_022.jpg\"\n",
    "\n",
    "# Path to the fine-tuned DETR model (relative to Code folder)\n",
    "DETR_MODEL_PATH = r\"..\\Models\\detr-finetuned-floorplans\"\n",
    "\n",
    "# Path to the SAM checkpoint (relative to Code folder)\n",
    "SAM_CHECKPOINT  = r\"..\\Models\\Sam_Checkpoint\\sam_vit_h_4b8939.pth\"\n",
    "\n",
    "# Path to the backgrounds directory (relative to Code folder)\n",
    "BACKGROUNDS_DIR = r\"..\\Data\\Label_Pics_for_Synthetic_Data_Generation\\backgrounds\"\n",
    "\n",
    "TARGET_LABELS = [\"1stdoor\", \"2sdoor\", \"toilet\", \"stove\", \"closet\", \"sink\"]  # run all of these\n",
    "DETR_THRESH = 0.25\n",
    "\n",
    "USE_SAM_MASK = True   # True = more precise (if SAM works), False = box mask\n",
    "BOX_PAD = 2           # padding for box + SAM box\n",
    "\n",
    "OUT_DIR = \"outputs_inpaint_from_backgrounds_all_labels\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SHOW_EACH = True     # True => show 3 images per label (can be slow)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def list_images(folder):\n",
    "    exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".webp\")\n",
    "    if not os.path.isdir(folder):\n",
    "        return []\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(exts)]\n",
    "\n",
    "def pick_background(bg_dir):\n",
    "    files = list_images(bg_dir)\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No images found in {bg_dir}\")\n",
    "    return Image.open(random.choice(files)).convert(\"RGB\")\n",
    "\n",
    "def expand_box_xyxy(box, W, H, pad):\n",
    "    x0, y0, x1, y1 = box\n",
    "    x0 = max(0, int(x0 - pad)); y0 = max(0, int(y0 - pad))\n",
    "    x1 = min(W, int(x1 + pad)); y1 = min(H, int(y1 + pad))\n",
    "    return np.array([x0, y0, x1, y1], dtype=np.int32)\n",
    "\n",
    "def draw_box(img_pil, box, color=(255, 0, 0), thickness=2):\n",
    "    arr = np.array(img_pil).copy()\n",
    "    x0, y0, x1, y1 = map(int, box)\n",
    "    cv2.rectangle(arr, (x0, y0), (x1, y1), color, thickness)\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "def box_mask(H, W, box):\n",
    "    x0, y0, x1, y1 = map(int, box)\n",
    "    m = np.zeros((H, W), dtype=np.uint8)\n",
    "    m[y0:y1, x0:x1] = 255\n",
    "    return m\n",
    "\n",
    "def alpha_blend_with_mask(src_rgb, bg_rgb, mask_uint8):\n",
    "    \"\"\"\n",
    "    src_rgb, bg_rgb: uint8 HxWx3\n",
    "    mask_uint8: uint8 HxW (0..255)\n",
    "    \"\"\"\n",
    "    m = (mask_uint8.astype(np.float32) / 255.0)[..., None]\n",
    "    out = (src_rgb.astype(np.float32) * (1.0 - m) + bg_rgb.astype(np.float32) * m)\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"[^\\w\\-\\.]+\", \"_\", s)\n",
    "    return s[:80] if len(s) > 80 else s\n",
    "\n",
    "# =========================\n",
    "# Load image once\n",
    "# =========================\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    raise FileNotFoundError(f\"Image not found at: {IMAGE_PATH}\")\n",
    "\n",
    "image_pil = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "W, H = image_pil.size\n",
    "img_np = np.array(image_pil)\n",
    "\n",
    "# Save original once\n",
    "image_pil.save(os.path.join(OUT_DIR, \"orig.png\"))\n",
    "\n",
    "# =========================\n",
    "# 1) DETR detect (single forward pass)\n",
    "# =========================\n",
    "print(f\"Loading DETR from: {DETR_MODEL_PATH}\")\n",
    "processor = DetrImageProcessor.from_pretrained(DETR_MODEL_PATH)\n",
    "detr = DetrForObjectDetection.from_pretrained(DETR_MODEL_PATH).to(DEVICE).eval()\n",
    "id2label = detr.config.id2label\n",
    "\n",
    "inputs = processor(images=image_pil, return_tensors=\"pt\").to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    outputs = detr(**inputs)\n",
    "\n",
    "target_sizes = torch.tensor([image_pil.size[::-1]], device=DEVICE)\n",
    "res = processor.post_process_object_detection(\n",
    "    outputs, target_sizes=target_sizes, threshold=DETR_THRESH\n",
    ")[0]\n",
    "\n",
    "# Collect all detections once\n",
    "all_dets = []\n",
    "for sc, lab, bx in zip(res[\"scores\"], res[\"labels\"], res[\"boxes\"]):\n",
    "    name = id2label[int(lab)]\n",
    "    b = bx.detach().cpu().numpy()\n",
    "    x0, y0, x1, y1 = b\n",
    "    area = max(1.0, (x1 - x0) * (y1 - y0))\n",
    "    all_dets.append((float(sc), float(area), b, name))\n",
    "\n",
    "print(f\"Found {len(all_dets)} detections above threshold={DETR_THRESH}\")\n",
    "\n",
    "# =========================\n",
    "# 2) Init SAM once (optional)\n",
    "# =========================\n",
    "predictor = None\n",
    "sam = None\n",
    "if USE_SAM_MASK:\n",
    "    print(f\"Loading SAM from: {SAM_CHECKPOINT}\")\n",
    "    if not os.path.exists(SAM_CHECKPOINT):\n",
    "        raise FileNotFoundError(f\"SAM checkpoint not found at: {SAM_CHECKPOINT}\")\n",
    "        \n",
    "    sam = sam_model_registry[\"vit_h\"](checkpoint=SAM_CHECKPOINT).to(DEVICE)\n",
    "    predictor = SamPredictor(sam)\n",
    "    predictor.set_image(img_np, image_format=\"RGB\")\n",
    "\n",
    "# =========================\n",
    "# 3) Loop over target labels\n",
    "# =========================\n",
    "for target_substr in TARGET_LABELS:\n",
    "    # Filter candidates by substring match\n",
    "    cands = []\n",
    "    for sc, area, b, name in all_dets:\n",
    "        if target_substr.lower() in name.lower():\n",
    "            cands.append((sc, area, b, name))\n",
    "\n",
    "    if not cands:\n",
    "        print(f\"Not found: '{target_substr}' (no detections). Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # pick best: highest score then largest area\n",
    "    cands.sort(key=lambda x: (x[0], x[1]), reverse=True)\n",
    "    best_score, best_area, best_box, best_name = cands[0]\n",
    "    best_box = expand_box_xyxy(best_box, W, H, pad=BOX_PAD)\n",
    "\n",
    "    print(f\"'{target_substr}' -> using {best_name}: score={best_score:.2f}, area={best_area:.1f}, box={best_box.tolist()}\")\n",
    "\n",
    "    # Build mask\n",
    "    if not USE_SAM_MASK:\n",
    "        mask = box_mask(H, W, best_box)\n",
    "    else:\n",
    "        try:\n",
    "            masks, _, _ = predictor.predict(\n",
    "                box=best_box.astype(np.float32)[None, :],\n",
    "                multimask_output=False\n",
    "            )\n",
    "            mask = (masks[0].astype(np.uint8) * 255)\n",
    "        except Exception as e:\n",
    "            # fall back to box mask, don't crash\n",
    "            print(f\"SAM failed for '{target_substr}' ({e}). Falling back to box mask.\")\n",
    "            mask = box_mask(H, W, best_box)\n",
    "\n",
    "    # Background + blend\n",
    "    try:\n",
    "        bg_pil = pick_background(BACKGROUNDS_DIR).resize((W, H), Image.Resampling.LANCZOS)\n",
    "    except Exception as e:\n",
    "        print(f\"Background loading failed ({e}). Skipping '{target_substr}'.\")\n",
    "        continue\n",
    "\n",
    "    bg_np = np.array(bg_pil)\n",
    "\n",
    "    # Feather edges\n",
    "    mask_feather = cv2.GaussianBlur(mask, (0, 0), sigmaX=1.0)\n",
    "\n",
    "    out_np = alpha_blend_with_mask(img_np, bg_np, mask_feather)\n",
    "    out_pil = Image.fromarray(out_np)\n",
    "\n",
    "    # Save per-label outputs\n",
    "    lbl_dir = os.path.join(OUT_DIR, safe_name(target_substr))\n",
    "    os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "    draw_box(image_pil, best_box).save(os.path.join(lbl_dir, \"box.png\"))\n",
    "    Image.fromarray(mask).save(os.path.join(lbl_dir, \"mask.png\"))\n",
    "    bg_pil.save(os.path.join(lbl_dir, \"bg_used.png\"))\n",
    "    out_pil.save(os.path.join(lbl_dir, \"result.png\"))\n",
    "\n",
    "    if SHOW_EACH:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1); plt.title(f\"Original ({target_substr})\"); plt.imshow(image_pil); plt.axis(\"off\")\n",
    "        plt.subplot(1, 3, 2); plt.title(\"Mask\"); plt.imshow(mask, cmap=\"gray\"); plt.axis(\"off\")\n",
    "        plt.subplot(1, 3, 3); plt.title(\"Result (BG inpaint)\"); plt.imshow(out_pil); plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# =========================\n",
    "# Cleanup\n",
    "# =========================\n",
    "try:\n",
    "    del inputs, outputs, detr, processor\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if predictor is not None:\n",
    "    try:\n",
    "        del predictor, sam\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nDONE Saved everything under: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef1a0a",
   "metadata": {},
   "source": [
    "# Patch-Based Replacement: Sink → Stove & Toilet → Stove\n",
    "\n",
    "This script produces **two separate edits** from the **same original floorplan**:\n",
    "1. **Sink → Stove**\n",
    "2. **Toilet → Stove**\n",
    "\n",
    "It then visualizes the results as **two triplets** (2 rows × 3 images):\n",
    "- **Original**\n",
    "- **Stove patch (cropped)**\n",
    "- **Result**\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- **Floorplan image**: `IMAGE_PATH`\n",
    "- **Fine-tuned DETR model**: `Models\\detr-finetuned-floorplans`\n",
    "- **External stove patches** (your generated symbols): `STOVE_DIR`  \n",
    "  Example: `Data\\Label_Pics_for_Synthetic_Data_Generation`\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "\n",
    "### Saved files (per change)\n",
    "Saved under: `OUT_DIR = outputs_sink_and_toilet_to_stove`\n",
    "\n",
    "For each change (`sink` / `toilet`) the code saves:\n",
    "- `{label}_orig.png` — original image\n",
    "- `{label}_box.png` — original image + detected bounding box\n",
    "- `{label}_stove_patch_cropped.png` — the selected stove patch after tight-cropping\n",
    "- `{label}_stove_mask_cropped.png` — ink-mask of the patch after cropping\n",
    "- `{label}_result.png` — final edited image\n",
    "\n",
    "### Visualization\n",
    "The script displays:\n",
    "- **Row 1**: Original → Patch → Result (**sink → stove**)\n",
    "- **Row 2**: Original → Patch → Result (**toilet → stove**)\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline (per replacement)\n",
    "\n",
    "### 1) Detect target object (DETR)\n",
    "- Run DETR on the input image.\n",
    "- Filter detections by `label == SOURCE_LABEL` (either `sink` or `toilet`).\n",
    "- Keep detections above `DETR_THRESH`.\n",
    "- Choose the best candidate:\n",
    "  - highest score first\n",
    "  - then largest area\n",
    "\n",
    "### 2) Expand and remove the object\n",
    "- Expand bounding box by `BOX_PAD` pixels.\n",
    "- Fill that region with **white** (background).\n",
    "\n",
    "### 3) Load a stove patch (external)\n",
    "- Randomly select an image from `STOVE_DIR`.\n",
    "- Convert patch to an **ink mask** using grayscale threshold (`INK_THRESH`):\n",
    "  - pixels darker than threshold are considered “ink”\n",
    "\n",
    "### 4) Tight-crop patch to ink\n",
    "- Find the smallest bounding box around ink pixels.\n",
    "- Crop both patch and mask to remove empty margins.\n",
    "\n",
    "### 5) Resize patch to fit the target box\n",
    "- Resize while keeping aspect ratio so it fits inside the detected bounding box.\n",
    "\n",
    "### 6) Paste with alpha blending\n",
    "- Use the mask as alpha:\n",
    "  - ink pixels are pasted\n",
    "  - background stays white\n",
    "- Optional soft edges via Gaussian blur (`FEATHER_SIGMA`).\n",
    "\n",
    "---\n",
    "\n",
    "## Notes / Clarifications\n",
    "\n",
    "### Are we using your generated images?\n",
    " **Yes.**  \n",
    "The replacement stove symbol is taken from `STOVE_DIR` (your generated patch dataset).\n",
    "\n",
    "### Are we cutting a stove from the original floorplan?\n",
    " **No.**  \n",
    "The code only detects **where to remove** (sink/toilet).  \n",
    "The stove comes from an external patch image, not from the input image.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Parameters\n",
    "\n",
    "- `DETR_THRESH` — detection confidence threshold  \n",
    "- `BOX_PAD` — padding added around detected bounding box  \n",
    "- `INK_THRESH` — ink detection threshold for patch masking  \n",
    "- `FEATHER_SIGMA` — soft edge blending (0 disables)  \n",
    "- `MIN_PATCH_SIZE` — ignores too-small patch images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "\n",
    "# 1. DETR Model Path (Relative to Code folder)\n",
    "DETR_MODEL_PATH = r\"..\\Models\\detr-finetuned-floorplans\"\n",
    "\n",
    "# 2. Image Path (Relative to Code folder)\n",
    "# Pointing to an example image in your 'images_before' folder\n",
    "IMAGE_PATH      = r\"..\\Data\\images_before\\image_022.jpg\"\n",
    "\n",
    "DETR_THRESH  = 0.25\n",
    "BOX_PAD      = 2\n",
    "\n",
    "# 3. Stove patches directory (Relative to Code folder)\n",
    "# Pointing to the stove folder inside Label_Pics...\n",
    "STOVE_DIR = r\"..\\Data\\Label_Pics_for_Synthetic_Data_Generation\\stove\"\n",
    "\n",
    "# Ink mask parameters\n",
    "INK_THRESH     = 220\n",
    "PATCH_DILATE   = 0\n",
    "FEATHER_SIGMA  = 0.6\n",
    "\n",
    "MIN_PATCH_SIZE = 64\n",
    "\n",
    "OUT_DIR = \"outputs_sink_and_toilet_to_stove\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def expand_box_xyxy(box, W, H, pad):\n",
    "    x0,y0,x1,y1 = box\n",
    "    x0 = max(0, int(x0-pad)); y0 = max(0, int(y0-pad))\n",
    "    x1 = min(W, int(x1+pad)); y1 = min(H, int(y1+pad))\n",
    "    return [x0,y0,x1,y1]\n",
    "\n",
    "def draw_box(img_pil, box, color=(255,0,0), thickness=2):\n",
    "    arr = np.array(img_pil).copy()\n",
    "    x0,y0,x1,y1 = map(int, box)\n",
    "    cv2.rectangle(arr, (x0,y0), (x1,y1), color, thickness)\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "def list_images(folder):\n",
    "    exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".webp\")\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"Warning: Folder not found: {folder}\")\n",
    "        return []\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(exts)]\n",
    "\n",
    "def pick_random_patch(folder, min_size=64, tries=50):\n",
    "    files = list_images(folder)\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No images found in {folder}\")\n",
    "    for _ in range(tries):\n",
    "        p = Image.open(random.choice(files)).convert(\"RGB\")\n",
    "        if min(p.size) >= min_size:\n",
    "            return p\n",
    "    return Image.open(random.choice(files)).convert(\"RGB\")\n",
    "\n",
    "def make_ink_mask(patch_rgb, ink_thresh=220, dilate=0):\n",
    "    gray = cv2.cvtColor(patch_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    mask = (gray < int(ink_thresh)).astype(np.uint8) * 255\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, k, iterations=1)\n",
    "\n",
    "    if dilate and dilate > 0:\n",
    "        k2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate*2+1, dilate*2+1))\n",
    "        mask = cv2.dilate(mask, k2, iterations=1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def tight_crop_to_mask(patch_rgb, mask, margin=2):\n",
    "    ys, xs = np.where(mask > 0)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        return patch_rgb, mask\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "    x0 = max(0, x0 - margin); y0 = max(0, y0 - margin)\n",
    "    x1 = min(mask.shape[1]-1, x1 + margin); y1 = min(mask.shape[0]-1, y1 + margin)\n",
    "    return patch_rgb[y0:y1+1, x0:x1+1], mask[y0:y1+1, x0:x1+1]\n",
    "\n",
    "def resize_keep_aspect(patch_rgb, mask, target_w, target_h):\n",
    "    ph, pw = patch_rgb.shape[:2]\n",
    "    scale = min(target_w / max(1, pw), target_h / max(1, ph))\n",
    "    nw = max(1, int(round(pw * scale)))\n",
    "    nh = max(1, int(round(ph * scale)))\n",
    "\n",
    "    patch_r = cv2.resize(\n",
    "        patch_rgb, (nw, nh),\n",
    "        interpolation=cv2.INTER_AREA if scale < 1 else cv2.INTER_CUBIC\n",
    "    )\n",
    "    mask_r = cv2.resize(mask, (nw, nh), interpolation=cv2.INTER_NEAREST)\n",
    "    return patch_r, mask_r\n",
    "\n",
    "def feather_mask(mask_uint8, sigma=0.6):\n",
    "    if sigma <= 0:\n",
    "        return mask_uint8\n",
    "    return cv2.GaussianBlur(mask_uint8, (0,0), sigmaX=float(sigma))\n",
    "\n",
    "def apply_replace_with_stove(image_pil, source_label, save_prefix):\n",
    "    \"\"\"\n",
    "    Detect `source_label`, remove it (white fill), paste a random stove patch.\n",
    "    Returns:\n",
    "      out_pil (result image),\n",
    "      stove_rgb_c (cropped patch for visualization),\n",
    "      box (used bbox)\n",
    "    Also saves debug artifacts under OUT_DIR with prefix.\n",
    "    \"\"\"\n",
    "    W, H = image_pil.size\n",
    "\n",
    "    # ---- DETR detect\n",
    "    inputs = processor(images=image_pil, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = detr(**inputs)\n",
    "\n",
    "    target_sizes = torch.tensor([image_pil.size[::-1]], device=DEVICE)\n",
    "    res = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=DETR_THRESH)[0]\n",
    "\n",
    "    cands = []\n",
    "    for sc, lab, bx in zip(res[\"scores\"], res[\"labels\"], res[\"boxes\"]):\n",
    "        name = id2label[int(lab)]\n",
    "        if name != source_label:\n",
    "            continue\n",
    "        b = bx.detach().cpu().numpy()\n",
    "        x0,y0,x1,y1 = b\n",
    "        area = max(1.0, (x1-x0)*(y1-y0))\n",
    "        cands.append((float(sc), float(area), b, name))\n",
    "\n",
    "    if not cands:\n",
    "        # Just a warning instead of crash, useful for testing different images\n",
    "        print(f\"Warning: No '{source_label}' detected in this image.\")\n",
    "        return image_pil, np.zeros((10,10,3), dtype=np.uint8), [0,0,1,1]\n",
    "\n",
    "    cands.sort(key=lambda x: (x[0], x[1]), reverse=True)\n",
    "    best_score, best_area, best_box, best_name = cands[0]\n",
    "\n",
    "    box = expand_box_xyxy(best_box, W, H, pad=BOX_PAD)\n",
    "    x0,y0,x1,y1 = box\n",
    "    bw, bh = (x1-x0), (y1-y0)\n",
    "\n",
    "    print(f\" [{source_label}] score={best_score:.2f}, box={box}\")\n",
    "\n",
    "    # ---- remove (white)\n",
    "    out = np.array(image_pil).copy()\n",
    "    out[y0:y1, x0:x1] = 255\n",
    "\n",
    "    # ---- load stove patch + mask + crop + resize + paste\n",
    "    try:\n",
    "        stove_pil = pick_random_patch(STOVE_DIR, min_size=MIN_PATCH_SIZE)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading stove patch: {e}\")\n",
    "        return image_pil, np.zeros((10,10,3), dtype=np.uint8), box\n",
    "\n",
    "    stove_rgb = np.array(stove_pil)\n",
    "\n",
    "    mask = make_ink_mask(stove_rgb, ink_thresh=INK_THRESH, dilate=PATCH_DILATE)\n",
    "    stove_rgb_c, mask_c = tight_crop_to_mask(stove_rgb, mask, margin=2)\n",
    "\n",
    "    patch_r, mask_r = resize_keep_aspect(stove_rgb_c, mask_c, bw, bh)\n",
    "    mask_r = feather_mask(mask_r, sigma=FEATHER_SIGMA)\n",
    "\n",
    "    ph, pw = patch_r.shape[:2]\n",
    "    px0 = x0 + (bw - pw)//2\n",
    "    py0 = y0 + (bh - ph)//2\n",
    "\n",
    "    px0 = max(0, min(W - pw, px0))\n",
    "    py0 = max(0, min(H - ph, py0))\n",
    "\n",
    "    region = out[py0:py0+ph, px0:px0+pw].astype(np.float32)\n",
    "    alpha = (mask_r.astype(np.float32) / 255.0)[..., None]\n",
    "    blended = region * (1.0 - alpha) + patch_r.astype(np.float32) * alpha\n",
    "    out[py0:py0+ph, px0:px0+pw] = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "\n",
    "    out_pil = Image.fromarray(out)\n",
    "\n",
    "    # ---- save debug files\n",
    "    image_pil.save(os.path.join(OUT_DIR, f\"{save_prefix}_orig.png\"))\n",
    "    draw_box(image_pil, box).save(os.path.join(OUT_DIR, f\"{save_prefix}_box.png\"))\n",
    "    out_pil.save(os.path.join(OUT_DIR, f\"{save_prefix}_result.png\"))\n",
    "\n",
    "    Image.fromarray(stove_rgb_c).save(os.path.join(OUT_DIR, f\"{save_prefix}_stove_patch_cropped.png\"))\n",
    "    Image.fromarray(mask_c).save(os.path.join(OUT_DIR, f\"{save_prefix}_stove_mask_cropped.png\"))\n",
    "\n",
    "    return out_pil, stove_rgb_c, box\n",
    "\n",
    "# =========================\n",
    "# Load DETR once\n",
    "# =========================\n",
    "print(f\"Loading DETR from: {DETR_MODEL_PATH}\")\n",
    "processor = DetrImageProcessor.from_pretrained(DETR_MODEL_PATH)\n",
    "detr = DetrForObjectDetection.from_pretrained(DETR_MODEL_PATH).to(DEVICE).eval()\n",
    "id2label = detr.config.id2label\n",
    "\n",
    "# =========================\n",
    "# Load image once\n",
    "# =========================\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    raise FileNotFoundError(f\"Image not found at: {IMAGE_PATH}\")\n",
    "\n",
    "print(f\"Loading image: {IMAGE_PATH}\")\n",
    "image_pil = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "\n",
    "# =========================\n",
    "# Run both replacements (separately, from the same original)\n",
    "# =========================\n",
    "print(\"Processing Sink replacement...\")\n",
    "result_sink,   stove_crop_sink,   box_sink   = apply_replace_with_stove(image_pil, \"sink\",   \"sink\")\n",
    "\n",
    "print(\"Processing Toilet replacement...\")\n",
    "result_toilet, stove_crop_toilet, box_toilet = apply_replace_with_stove(image_pil, \"toilet\", \"toilet\")\n",
    "\n",
    "# cleanup model objects\n",
    "del detr, processor\n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Show: 2 triplets (sink + toilet)\n",
    "# =========================\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Triplet 1: sink -> stove\n",
    "plt.subplot(2,3,1); plt.title(\"Original (sink)\"); plt.imshow(image_pil); plt.axis(\"off\")\n",
    "plt.subplot(2,3,2); plt.title(\"Stove patch (cropped)\"); plt.imshow(Image.fromarray(stove_crop_sink)); plt.axis(\"off\")\n",
    "plt.subplot(2,3,3); plt.title(\"Result (sink -> stove)\"); plt.imshow(result_sink); plt.axis(\"off\")\n",
    "\n",
    "# Triplet 2: toilet -> stove\n",
    "plt.subplot(2,3,4); plt.title(\"Original (toilet)\"); plt.imshow(image_pil); plt.axis(\"off\")\n",
    "plt.subplot(2,3,5); plt.title(\"Stove patch (cropped)\"); plt.imshow(Image.fromarray(stove_crop_toilet)); plt.axis(\"off\")\n",
    "plt.subplot(2,3,6); plt.title(\"Result (toilet -> stove)\"); plt.imshow(result_toilet); plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\" Saved artifacts to {os.path.abspath(OUT_DIR)}\")\n",
    "print(\"DONE \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6518e98",
   "metadata": {},
   "source": [
    "# Add Closet Near Walls (Auto-Adaptive, Non-Wall Aware)\n",
    "\n",
    "This script **copies an existing closet symbol from the same floorplan image** and pastes it **only near walls**, while avoiding:\n",
    "- text inside rooms\n",
    "- other objects (non-wall ink)\n",
    "- overlaps with existing symbols\n",
    "\n",
    "It uses a **fine-tuned DETR** model to detect closets, builds **wall maps + interior mask**, separates **wall ink vs. non-wall ink**, then searches for the best valid placement.\n",
    "\n",
    "---\n",
    "\n",
    "##  What this script does\n",
    "\n",
    "1. **Loads a floorplan image** (`IMAGE_PATH`)\n",
    "2. Runs **DETR object detection** to find instances of `closet`\n",
    "3. Chooses the best detected closet as a **template**\n",
    "4. Builds:\n",
    "   - `thick_map` (wall map)\n",
    "   - `interior_mask` (inside the apartment, based on walls)\n",
    "   - `wall_ink` (walls only)\n",
    "   - `nonwall_ink` (text + furniture + symbols, excluding walls)\n",
    "5. Searches for a placement that:\n",
    "   - is **inside the apartment**\n",
    "   - is **near walls**\n",
    "   - avoids **non-wall ink** (objects/text)\n",
    "   - minimizes overlaps\n",
    "6. Pastes the closet and saves outputs to `OUT_DIR`\n",
    "\n",
    "---\n",
    "\n",
    "##  Inputs / Outputs\n",
    "\n",
    "### Inputs\n",
    "- `IMAGE_PATH`: floorplan PNG/JPG\n",
    "- `DETR_MODEL_PATH`: folder containing the fine-tuned DETR model\n",
    "\n",
    "### Outputs (saved under `OUT_DIR`)\n",
    "- `result.png` — final floorplan with a pasted closet  \n",
    "- `result_box.png` — debug: source closet (blue box) + placed closet (red box)\n",
    "- `thick_walls_clean.png` — detected walls map\n",
    "- `interior_mask.png` — computed interior region\n",
    "- `nonwall_ink.png` — text/objects ink excluding walls\n",
    "- `wall_ink.png` — wall ink mask\n",
    "- `placement_mask_band_*.png` — wall-band placement masks per band tested\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "✅ Template: box=(581, 427, 611, 490) score=0.92 size=30x63\n",
      "✅ Scale policy: target_scale=1.000, SCALES=['0.900', '1.000', '1.100']\n",
      "✅ Placement: (446,86) band=18 scale=0.900 nonwallBlack=0.000 inkInside=1.000 overlap=0.0000 px=0 meanWallDist=9.29 touchFrac=0.081 ringInk=0\n",
      "✅ DONE. Saved to: .\\outputs_add_closet_wall_only_v2\n"
     ]
    }
   ],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "# Using relative paths for better portability\n",
    "IMAGE_PATH      = r\"..\\Data\\images_before\\image_008.jpg\"\n",
    "DETR_MODEL_PATH = r\"..\\Models\\detr-finetuned-floorplans\"\n",
    "\n",
    "TARGET_LABEL = \"closet\"\n",
    "DETR_THRESH  = 0.20\n",
    "\n",
    "OUT_DIR = r\"outputs_add_closet_wall_only_v2\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Wall detection kernel size\n",
    "WALL_KERNEL = 11\n",
    "\n",
    "# Scanning parameters\n",
    "MARGIN = 10\n",
    "STRIDE = 4\n",
    "\n",
    "# Interior constraint (closet ink must be inside the detected room)\n",
    "MIN_INK_INSIDE_FRAC = 0.99\n",
    "\n",
    "# Coarse \"busy\" filter - ignores walls now, stricter on other objects\n",
    "MAX_NONWALL_BLACK_FRAC = 0.06 \n",
    "\n",
    "# Overlap avoidance settings\n",
    "EXISTING_DILATE = 3\n",
    "MAX_OVERLAP_PIXELS_BASE = 10\n",
    "MAX_OVERLAP_FRAC_BASE   = 0.03\n",
    "\n",
    "# Keep-away ring settings (distance from text/other objects)\n",
    "RING_DILATE = 10\n",
    "MAX_RING_OVERLAP_PIXELS = 25\n",
    "MAX_RING_OVERLAP_FRAC   = 0.03\n",
    "\n",
    "# Mask blending softness\n",
    "FEATHER_SIGMA = 0.6\n",
    "\n",
    "# Template filtering parameters\n",
    "MIN_TEMPLATE_SIZE = 18\n",
    "MAX_TEMPLATE_REL = 0.45\n",
    "BOX_PAD = 2\n",
    "\n",
    "# Near-wall bands (distance to walls to check)\n",
    "BANDS = [10, 14, 18, 24, 30, 40, 55]\n",
    "\n",
    "# Adaptive overlap relaxation\n",
    "OV_PIX_LIST  = [MAX_OVERLAP_PIXELS_BASE, 16, 24, 36]\n",
    "OV_FRAC_LIST = [MAX_OVERLAP_FRAC_BASE,   0.04, 0.06, 0.08]\n",
    "\n",
    "# Must be touching the wall constraints\n",
    "WALL_TOUCH_MAX_DIST = 3.0\n",
    "MIN_WALL_TOUCH_FRAC = 0.03\n",
    "\n",
    "# Thick-wall cleanup thresholds\n",
    "THICK_MIN_AREA       = 2500\n",
    "THICK_MIN_LONG_SIDE  = 160\n",
    "THICK_MIN_SHORT_SIDE = 6\n",
    "\n",
    "# Wall/Non-wall separation settings\n",
    "WALL_INK_DILATE = 3   # Expand walls slightly to cleanly separate from other ink\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def expand_box_xyxy(box, W, H, pad):\n",
    "    x0,y0,x1,y1 = box\n",
    "    x0 = max(0, int(x0-pad)); y0 = max(0, int(y0-pad))\n",
    "    x1 = min(W, int(x1+pad)); y1 = min(H, int(y1+pad))\n",
    "    return [x0,y0,x1,y1]\n",
    "\n",
    "def filter_thick_map_components(thick_map, min_area=1500, min_long_side=120, min_short_side=6):\n",
    "    # Filters out small noise from the wall map\n",
    "    bw = (thick_map > 0).astype(np.uint8)\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(bw, connectivity=8)\n",
    "    out = np.zeros_like(bw)\n",
    "    for i in range(1, num):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        long_side = max(w, h)\n",
    "        short_side = min(w, h)\n",
    "        if area < min_area: \n",
    "            continue\n",
    "        if long_side < min_long_side:\n",
    "            continue\n",
    "        if short_side < min_short_side:\n",
    "            continue\n",
    "        out[labels == i] = 1\n",
    "    return (out * 255).astype(np.uint8)\n",
    "\n",
    "def build_line_maps(img_bgr, wall_kernel):\n",
    "    # Extracts potential walls and cleans them up\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, bin_inv = cv2.threshold(gray, 235, 255, cv2.THRESH_BINARY_INV) \n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (wall_kernel, wall_kernel))\n",
    "    thick = cv2.morphologyEx(bin_inv, cv2.MORPH_CLOSE, k, iterations=1)\n",
    "    thick = cv2.erode(thick, np.ones((3,3), np.uint8), iterations=1)\n",
    "\n",
    "    thick_clean = filter_thick_map_components(\n",
    "        thick,\n",
    "        min_area=THICK_MIN_AREA,\n",
    "        min_long_side=THICK_MIN_LONG_SIDE,\n",
    "        min_short_side=THICK_MIN_SHORT_SIDE\n",
    "    )\n",
    "    return bin_inv, thick_clean\n",
    "\n",
    "def build_interior_from_walls(thick_map, close_gaps=13, wall_dilate=2):\n",
    "    # Floods the image to find the \"interior\" of the floorplan\n",
    "    H, W = thick_map.shape[:2]\n",
    "    walls = (thick_map > 0).astype(np.uint8) * 255\n",
    "\n",
    "    if wall_dilate > 0:\n",
    "        k = cv2.getStructuringElement(cv2.MORPH_RECT, (2*wall_dilate+1, 2*wall_dilate+1))\n",
    "        walls = cv2.dilate(walls, k, iterations=1)\n",
    "\n",
    "    k2 = cv2.getStructuringElement(cv2.MORPH_RECT, (close_gaps, close_gaps))\n",
    "    walls_closed = cv2.morphologyEx(walls, cv2.MORPH_CLOSE, k2, iterations=1)\n",
    "\n",
    "    free = cv2.bitwise_not(walls_closed)\n",
    "    ff = free.copy()\n",
    "    mask = np.zeros((H+2, W+2), dtype=np.uint8)\n",
    "\n",
    "    # Floodfill from corners\n",
    "    for seed in [(0,0), (W-1,0), (0,H-1), (W-1,H-1)]:\n",
    "        if ff[seed[1], seed[0]] == 255:\n",
    "            cv2.floodFill(ff, mask, seedPoint=seed, newVal=0)\n",
    "\n",
    "    interior = ff\n",
    "    return interior, walls_closed\n",
    "\n",
    "def build_placement_mask(interior_mask, thick_map, wall_band):\n",
    "    # Creates a mask of valid placement areas near walls\n",
    "    thick_bin = (thick_map > 0).astype(np.uint8)\n",
    "    dist = cv2.distanceTransform(1 - thick_bin, cv2.DIST_L2, 3)\n",
    "    near_wall = (dist <= wall_band).astype(np.uint8) * 255\n",
    "    placement = cv2.bitwise_and(interior_mask, near_wall)\n",
    "    return placement\n",
    "\n",
    "def mask_from_crop_nonwhite(crop_bgr, feather_sigma):\n",
    "    # Creates a mask from the non-white pixels of a crop\n",
    "    gray = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    hard = cv2.inRange(gray, 0, 245)\n",
    "    hard = cv2.morphologyEx(hard, cv2.MORPH_CLOSE, np.ones((3,3), np.uint8), iterations=1)\n",
    "    soft = hard.copy()\n",
    "    if feather_sigma and feather_sigma > 0:\n",
    "        soft = cv2.GaussianBlur(soft, (0,0), sigmaX=float(feather_sigma))\n",
    "    return hard, soft\n",
    "\n",
    "def alpha_paste(base_bgr, crop_bgr, mask_uint8, x, y):\n",
    "    # Pastes a crop onto the base image using alpha blending\n",
    "    h, w = crop_bgr.shape[:2]\n",
    "    roi = base_bgr[y:y+h, x:x+w]\n",
    "    m = (mask_uint8.astype(np.float32) / 255.0)[..., None]\n",
    "    out = roi.astype(np.float32) * (1.0 - m) + crop_bgr.astype(np.float32) * m\n",
    "    base_bgr[y:y+h, x:x+w] = np.clip(out, 0, 255).astype(np.uint8)\n",
    "    return base_bgr\n",
    "\n",
    "def resize_template(template, mask_hard, mask_soft, scale):\n",
    "    # Resizes the template and its masks\n",
    "    h, w = template.shape[:2]\n",
    "    nw = max(8, int(w * scale))\n",
    "    nh = max(8, int(h * scale))\n",
    "    t2  = cv2.resize(template,  (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "    mh2 = cv2.resize(mask_hard, (nw, nh), interpolation=cv2.INTER_NEAREST)\n",
    "    ms2 = cv2.resize(mask_soft, (nw, nh), interpolation=cv2.INTER_NEAREST)\n",
    "    return t2, mh2, ms2\n",
    "\n",
    "def choose_template_highest_score(templates):\n",
    "    templates.sort(key=lambda t: t[\"score\"], reverse=True)\n",
    "    return templates[0]\n",
    "\n",
    "def make_ring_mask(mh_uint8, ring_dilate):\n",
    "    # Creates a ring mask around the object for spacing checks\n",
    "    mh = (mh_uint8 > 0).astype(np.uint8)\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*ring_dilate+1, 2*ring_dilate+1))\n",
    "    dil = cv2.dilate(mh, k, iterations=1)\n",
    "    ring = (dil > 0).astype(np.uint8) - (mh > 0).astype(np.uint8)\n",
    "    ring[ring < 0] = 0\n",
    "    return ring\n",
    "\n",
    "def find_best_spot_wall_only(\n",
    "    interior_mask, placement_mask,\n",
    "    thick_map,\n",
    "    all_ink, nonwall_ink, \n",
    "    template_mask_hard, roi_w, roi_h,\n",
    "    margin, stride,\n",
    "    max_nonwall_black_frac,\n",
    "    existing_dilate,\n",
    "    max_overlap_pixels, max_overlap_frac,\n",
    "    wall_band,\n",
    "    min_ink_inside_frac,\n",
    "    wall_touch_max_dist, min_wall_touch_frac,\n",
    "    ring_dilate, max_ring_overlap_pixels, max_ring_overlap_frac\n",
    "):\n",
    "    H, W = interior_mask.shape[:2]\n",
    "\n",
    "    # Dilate NON-WALL ink for collision / ring tests\n",
    "    if existing_dilate and existing_dilate > 0:\n",
    "        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*existing_dilate+1, 2*existing_dilate+1))\n",
    "        nonwall_ink_dil = cv2.dilate(nonwall_ink, k, iterations=1)\n",
    "    else:\n",
    "        nonwall_ink_dil = nonwall_ink\n",
    "\n",
    "    # Distance map to WALLS\n",
    "    thick_bin = (thick_map > 0).astype(np.uint8)\n",
    "    dist_to_wall = cv2.distanceTransform(1 - thick_bin, cv2.DIST_L2, 3)\n",
    "\n",
    "    mh = (template_mask_hard > 0).astype(np.uint8)\n",
    "    mh_sum = int(mh.sum())\n",
    "    if mh_sum == 0:\n",
    "        return None\n",
    "\n",
    "    ring = make_ring_mask(template_mask_hard, ring_dilate)\n",
    "    ring_sum = int(ring.sum()) if ring is not None else 0\n",
    "\n",
    "    best = None\n",
    "    best_score = -1e18\n",
    "\n",
    "    # Scan grid for best placement\n",
    "    for y in range(margin, H - roi_h - margin, stride):\n",
    "        for x in range(margin, W - roi_w - margin, stride):\n",
    "\n",
    "            cx = x + roi_w // 2\n",
    "            cy = y + roi_h // 2\n",
    "            if placement_mask[cy, cx] == 0:\n",
    "                continue\n",
    "\n",
    "            # Busy check ONLY on non-wall ink\n",
    "            roi_nonwall = nonwall_ink[y:y+roi_h, x:x+roi_w]\n",
    "            nonwall_black_frac = float((roi_nonwall > 0).mean())\n",
    "            if nonwall_black_frac > max_nonwall_black_frac:\n",
    "                continue\n",
    "\n",
    "            # 1) Closet ink inside interior check\n",
    "            roi_int = (interior_mask[y:y+roi_h, x:x+roi_w] > 0).astype(np.uint8)\n",
    "            inside_on_ink = roi_int[mh > 0]\n",
    "            if inside_on_ink.size == 0:\n",
    "                continue\n",
    "            ink_inside_frac = float(inside_on_ink.mean())\n",
    "            if ink_inside_frac < min_ink_inside_frac:\n",
    "                continue\n",
    "\n",
    "            # 2) Near wall check (mean dist + touch)\n",
    "            roi_dist = dist_to_wall[y:y+roi_h, x:x+roi_w]\n",
    "            ink_dist = roi_dist[mh > 0]\n",
    "            if ink_dist.size == 0:\n",
    "                continue\n",
    "            if float(ink_dist.mean()) > float(wall_band):\n",
    "                continue\n",
    "            touch_frac = float((ink_dist <= wall_touch_max_dist).mean())\n",
    "            if touch_frac < min_wall_touch_frac:\n",
    "                continue\n",
    "\n",
    "            # 3) Overlap UNDER closet ink — only against NON-WALL ink\n",
    "            roi_exist = (nonwall_ink_dil[y:y+roi_h, x:x+roi_w] > 0).astype(np.uint8)\n",
    "            overlap_pixels = int((roi_exist * mh).sum())\n",
    "            if overlap_pixels > max_overlap_pixels:\n",
    "                continue\n",
    "            overlap_frac = overlap_pixels / float(mh_sum)\n",
    "            if overlap_frac > max_overlap_frac:\n",
    "                continue\n",
    "\n",
    "            # 4) Ring keep-away — only against NON-WALL ink\n",
    "            ring_overlap = 0\n",
    "            ring_overlap_frac = 0.0\n",
    "            if ring_sum > 0:\n",
    "                ring_overlap = int((roi_exist * ring).sum())\n",
    "                if ring_overlap > max_ring_overlap_pixels:\n",
    "                    continue\n",
    "                ring_overlap_frac = ring_overlap / float(ring_sum)\n",
    "                if ring_overlap_frac > max_ring_overlap_frac:\n",
    "                    continue\n",
    "\n",
    "            # Calculate score\n",
    "            score = (\n",
    "                (1.0 - nonwall_black_frac) * 1.5 +\n",
    "                (1.0 - overlap_frac) * 4.0 +\n",
    "                (1.0 - ring_overlap_frac) * 2.5 +\n",
    "                (1.0 - min(1.0, float(ink_dist.mean()) / float(wall_band))) * 1.5 +\n",
    "                touch_frac * 1.0 +\n",
    "                ink_inside_frac * 0.5\n",
    "            )\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best = (x, y, nonwall_black_frac, ink_inside_frac, overlap_frac, overlap_pixels,\n",
    "                        float(ink_dist.mean()), touch_frac, ring_overlap)\n",
    "\n",
    "    return best\n",
    "\n",
    "# =========================\n",
    "# 1) Load Image\n",
    "# =========================\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    raise FileNotFoundError(f\"Image not found at {IMAGE_PATH}\")\n",
    "\n",
    "img_pil = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "img_bgr = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "H, W = img_bgr.shape[:2]\n",
    "\n",
    "# =========================\n",
    "# 2) DETR Template Extraction\n",
    "# =========================\n",
    "print(f\"Loading DETR model from: {DETR_MODEL_PATH}\")\n",
    "processor = DetrImageProcessor.from_pretrained(DETR_MODEL_PATH)\n",
    "detr = DetrForObjectDetection.from_pretrained(DETR_MODEL_PATH).to(DEVICE).eval()\n",
    "id2label = detr.config.id2label\n",
    "\n",
    "inputs = processor(images=img_pil, return_tensors=\"pt\").to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    outputs = detr(**inputs)\n",
    "\n",
    "target_sizes = torch.tensor([img_pil.size[::-1]], device=DEVICE)\n",
    "res = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=DETR_THRESH)[0]\n",
    "\n",
    "del detr, processor, inputs, outputs\n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "templates = []\n",
    "for sc, lab, bx in zip(res[\"scores\"], res[\"labels\"], res[\"boxes\"]):\n",
    "    if id2label[int(lab)] != TARGET_LABEL:\n",
    "        continue\n",
    "    b = expand_box_xyxy(bx.detach().cpu().numpy(), W, H, BOX_PAD)\n",
    "    x0,y0,x1,y1 = map(int, b)\n",
    "    crop = img_bgr[y0:y1, x0:x1].copy()\n",
    "    if crop.size == 0:\n",
    "        continue\n",
    "    th, tw = crop.shape[:2]\n",
    "    if th < MIN_TEMPLATE_SIZE or tw < MIN_TEMPLATE_SIZE:\n",
    "        continue\n",
    "    if tw > W * MAX_TEMPLATE_REL or th > H * MAX_TEMPLATE_REL:\n",
    "        continue\n",
    "    mh, ms = mask_from_crop_nonwhite(crop, FEATHER_SIGMA)\n",
    "    templates.append({\"crop\": crop, \"mask_hard\": mh, \"mask_soft\": ms, \"box\": (x0,y0,x1,y1), \"score\": float(sc)})\n",
    "\n",
    "if not templates:\n",
    "    print(f\"Warning: No closets detected with threshold {DETR_THRESH}. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "canon = choose_template_highest_score(templates)\n",
    "template = canon[\"crop\"]\n",
    "template_mask_hard = canon[\"mask_hard\"]\n",
    "template_mask_soft = canon[\"mask_soft\"]\n",
    "sx0,sy0,sx1,sy1 = canon[\"box\"]\n",
    "print(f\"Selected Template: score={canon['score']:.2f}, size={template.shape[1]}x{template.shape[0]}\")\n",
    "\n",
    "# Calculate proportional scaling\n",
    "ws = [t[\"box\"][2] - t[\"box\"][0] for t in templates]\n",
    "hs = [t[\"box\"][3] - t[\"box\"][1] for t in templates]\n",
    "med_w, med_h = float(np.median(ws)), float(np.median(hs))\n",
    "base_h, base_w = template.shape[:2]\n",
    "target_scale = min(med_w / max(1.0, base_w), med_h / max(1.0, base_h))\n",
    "target_scale = max(0.5, min(1.2, float(target_scale)))\n",
    "SCALES = [target_scale * s for s in [0.9, 1.0, 1.1]]\n",
    "print(f\"Scale Settings: target_scale={target_scale:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 3) Build Maps\n",
    "# =========================\n",
    "bin_inv_lines, thick_map = build_line_maps(img_bgr, WALL_KERNEL)\n",
    "interior_mask, walls_closed = build_interior_from_walls(thick_map, close_gaps=13, wall_dilate=2)\n",
    "\n",
    "# Separate wall ink from non-wall ink\n",
    "all_ink = (bin_inv_lines > 0).astype(np.uint8) * 255\n",
    "wall_ink = (thick_map > 0).astype(np.uint8) * 255\n",
    "\n",
    "if WALL_INK_DILATE > 0:\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*WALL_INK_DILATE+1, 2*WALL_INK_DILATE+1))\n",
    "    wall_ink = cv2.dilate(wall_ink, k, iterations=1)\n",
    "\n",
    "nonwall_ink = cv2.bitwise_and(all_ink, cv2.bitwise_not(wall_ink))\n",
    "\n",
    "# Save debug images\n",
    "cv2.imwrite(os.path.join(OUT_DIR, \"orig.png\"), cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite(os.path.join(OUT_DIR, \"bin_inv_lines.png\"), bin_inv_lines)\n",
    "cv2.imwrite(os.path.join(OUT_DIR, \"thick_walls_clean.png\"), thick_map)\n",
    "cv2.imwrite(os.path.join(OUT_DIR, \"interior_mask.png\"), interior_mask)\n",
    "cv2.imwrite(os.path.join(OUT_DIR, \"wall_ink.png\"), wall_ink)\n",
    "cv2.imwrite(os.path.join(OUT_DIR, \"nonwall_ink.png\"), nonwall_ink)\n",
    "\n",
    "# =========================\n",
    "# 4) Search for Placement\n",
    "# =========================\n",
    "best = None\n",
    "chosen_scale = None\n",
    "chosen_band = None\n",
    "chosen_ov_pix = None\n",
    "chosen_ov_frac = None\n",
    "\n",
    "print(\"Searching for placement...\")\n",
    "\n",
    "for band in BANDS:\n",
    "    placement_mask = build_placement_mask(interior_mask, thick_map, wall_band=band)\n",
    "    \n",
    "    # Save debug mask for this band\n",
    "    cv2.imwrite(os.path.join(OUT_DIR, f\"placement_mask_band_{band}.png\"), placement_mask)\n",
    "\n",
    "    if int((placement_mask > 0).sum()) < 500:\n",
    "        continue\n",
    "\n",
    "    for ov_pix in OV_PIX_LIST:\n",
    "        for ov_frac in OV_FRAC_LIST:\n",
    "            for sc in SCALES:\n",
    "                t_try, mh_try, ms_try = resize_template(template, template_mask_hard, template_mask_soft, sc)\n",
    "                roi_h, roi_w = t_try.shape[:2]\n",
    "\n",
    "                best_try = find_best_spot_wall_only(\n",
    "                    interior_mask=interior_mask,\n",
    "                    placement_mask=placement_mask,\n",
    "                    thick_map=thick_map,\n",
    "                    all_ink=all_ink,\n",
    "                    nonwall_ink=nonwall_ink,\n",
    "                    template_mask_hard=mh_try,\n",
    "                    roi_w=roi_w, roi_h=roi_h,\n",
    "                    margin=MARGIN, stride=STRIDE,\n",
    "                    max_nonwall_black_frac=MAX_NONWALL_BLACK_FRAC,\n",
    "                    existing_dilate=EXISTING_DILATE,\n",
    "                    max_overlap_pixels=ov_pix,\n",
    "                    max_overlap_frac=ov_frac,\n",
    "                    wall_band=band,\n",
    "                    min_ink_inside_frac=MIN_INK_INSIDE_FRAC,\n",
    "                    wall_touch_max_dist=WALL_TOUCH_MAX_DIST,\n",
    "                    min_wall_touch_frac=MIN_WALL_TOUCH_FRAC,\n",
    "                    ring_dilate=RING_DILATE,\n",
    "                    max_ring_overlap_pixels=MAX_RING_OVERLAP_PIXELS,\n",
    "                    max_ring_overlap_frac=MAX_RING_OVERLAP_FRAC\n",
    "                )\n",
    "\n",
    "                if best_try is not None:\n",
    "                    best = best_try\n",
    "                    template, template_mask_hard, template_mask_soft = t_try, mh_try, ms_try\n",
    "                    chosen_scale = sc\n",
    "                    chosen_band = band\n",
    "                    chosen_ov_pix = ov_pix\n",
    "                    chosen_ov_frac = ov_frac\n",
    "                    break\n",
    "            if best is not None: break\n",
    "        if best is not None: break\n",
    "    if best is not None: break\n",
    "\n",
    "if best is None:\n",
    "    raise RuntimeError(\n",
    "        \"No suitable placement found.\\n\"\n",
    "        \"Try relaxing these parameters:\\n\"\n",
    "        \"1) MAX_NONWALL_BLACK_FRAC\\n\"\n",
    "        \"2) RING_DILATE\\n\"\n",
    "        \"3) MIN_WALL_TOUCH_FRAC\\n\"\n",
    "        \"4) Add larger BANDS\"\n",
    "    )\n",
    "\n",
    "px, py, nonwall_black_frac, ink_inside_frac, ov_f, ov_p, mean_dist, touch_frac, ring_overlap = best\n",
    "roi_h, roi_w = template.shape[:2]\n",
    "\n",
    "print(f\"Placement Found: ({px},{py})\")\n",
    "print(f\"  Band: {chosen_band}, Scale: {chosen_scale:.3f}\")\n",
    "print(f\"  Non-wall Black Frac: {nonwall_black_frac:.3f}\")\n",
    "print(f\"  Ink Inside Frac: {ink_inside_frac:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 5) Paste and Save\n",
    "# =========================\n",
    "out = img_bgr.copy()\n",
    "out = alpha_paste(out, template, template_mask_soft, px, py)\n",
    "\n",
    "viz = out.copy()\n",
    "cv2.rectangle(viz, (sx0,sy0), (sx1,sy1), (255,0,0), 2)\n",
    "cv2.rectangle(viz, (px,py), (px+roi_w, py+roi_h), (0,0,255), 2)\n",
    "\n",
    "cv2.imwrite(os.path.join(OUT_DIR, \"result.png\"), out)\n",
    "cv2.imwrite(os.path.join(OUT_DIR, \"result_box.png\"), viz)\n",
    "\n",
    "print(f\"Done. Results saved to: {os.path.abspath(OUT_DIR)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
