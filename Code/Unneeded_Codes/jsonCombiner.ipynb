{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9ccaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping Categories...\n",
      "Base Max Image ID: 301\n",
      "Base Max Ann ID: 2980\n",
      "Standardizing file_name for file 1...\n",
      "Merging and standardizing file_name for file 2...\n",
      "✅ Success! Merged file saved to: C:\\Users\\adiha\\Desktop\\GenAi\\annotations\\merged_annotations0-460.json\n",
      "   Total Images: 461\n",
      "   Total Annotations: 5192\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def merge_coco_files(file1_path, file2_path, output_path):\n",
    "    # Folder prefix you want in ALL file_name fields\n",
    "    target_folder = \"dataset_for_labeling/\"\n",
    "\n",
    "    def normalize_file_name(path_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Always return: dataset_for_labeling/<basename>\n",
    "        Works for paths like:\n",
    "        - \"image_302.png\"\n",
    "        - \"dataset_for_labeling/image_302.png\"\n",
    "        - \"C:\\\\something\\\\dataset_for_labeling\\\\image_302.png\"\n",
    "        - \"some/other/folder/image_302.png\"\n",
    "        \"\"\"\n",
    "        base = os.path.basename(path_str.replace(\"\\\\\", \"/\"))\n",
    "        return target_folder + base\n",
    "\n",
    "    # 1. Load both JSON files\n",
    "    with open(file1_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data1 = json.load(f)\n",
    "\n",
    "    with open(file2_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data2 = json.load(f)\n",
    "\n",
    "    # 2. Verify / map categories by name\n",
    "    cat_map = {}\n",
    "    name_to_id_1 = {cat[\"name\"]: cat[\"id\"] for cat in data1.get(\"categories\", [])}\n",
    "\n",
    "    print(\"Mapping Categories...\")\n",
    "    for cat2 in data2.get(\"categories\", []):\n",
    "        name = cat2[\"name\"]\n",
    "        if name in name_to_id_1:\n",
    "            cat_map[cat2[\"id\"]] = name_to_id_1[name]\n",
    "        else:\n",
    "            new_id = max([c[\"id\"] for c in data1[\"categories\"]], default=0) + 1\n",
    "            new_cat = cat2.copy()\n",
    "            new_cat[\"id\"] = new_id\n",
    "            data1[\"categories\"].append(new_cat)\n",
    "            cat_map[cat2[\"id\"]] = new_id\n",
    "            name_to_id_1[name] = new_id\n",
    "            print(f\"  - Added new category: {name} (ID: {new_id})\")\n",
    "\n",
    "    # 3. Find max IDs in file1\n",
    "    max_img_id = max([img[\"id\"] for img in data1.get(\"images\", [])], default=0)\n",
    "    max_ann_id = max([ann[\"id\"] for ann in data1.get(\"annotations\", [])], default=0)\n",
    "\n",
    "    print(f\"Base Max Image ID: {max_img_id}\")\n",
    "    print(f\"Base Max Ann ID: {max_ann_id}\")\n",
    "\n",
    "    # 4. Standardize paths for file1 images\n",
    "    print(\"Standardizing file_name for file 1...\")\n",
    "    for img in data1.get(\"images\", []):\n",
    "        img[\"file_name\"] = normalize_file_name(img.get(\"file_name\", \"\"))\n",
    "\n",
    "    # 5. Process Images from File 2 (re-id + normalize file_name)\n",
    "    img_id_map = {}\n",
    "\n",
    "    print(\"Merging and standardizing file_name for file 2...\")\n",
    "    for img in data2.get(\"images\", []):\n",
    "        old_id = img[\"id\"]\n",
    "        max_img_id += 1\n",
    "        new_id = max_img_id\n",
    "\n",
    "        img_id_map[old_id] = new_id\n",
    "\n",
    "        img[\"id\"] = new_id\n",
    "        img[\"file_name\"] = normalize_file_name(img.get(\"file_name\", \"\"))\n",
    "\n",
    "        data1[\"images\"].append(img)\n",
    "\n",
    "    # 6. Process Annotations from File 2\n",
    "    for ann in data2.get(\"annotations\", []):\n",
    "        max_ann_id += 1\n",
    "        ann[\"id\"] = max_ann_id\n",
    "        ann[\"image_id\"] = img_id_map[ann[\"image_id\"]]\n",
    "        ann[\"category_id\"] = cat_map[ann[\"category_id\"]]\n",
    "        data1[\"annotations\"].append(ann)\n",
    "\n",
    "    # 7. Save Result\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data1, f, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ Success! Merged file saved to: {output_path}\")\n",
    "    print(f\"   Total Images: {len(data1['images'])}\")\n",
    "    print(f\"   Total Annotations: {len(data1['annotations'])}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file1 = r\"C:\\Users\\adiha\\Desktop\\GenAi\\annotations\\merged_annotations0-300.json\"\n",
    "    file2 = r\"C:\\Users\\adiha\\Desktop\\GenAi\\annotations\\instances_default301-460.json\"\n",
    "    output = r\"C:\\Users\\adiha\\Desktop\\GenAi\\annotations\\merged_annotations0-460.json\"\n",
    "\n",
    "    merge_coco_files(file1, file2, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
